{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20151230-predict-income-from-census\n",
    "\n",
    "Related post:  \n",
    "https://stharrold.github.io/20151230-predict-income-from-census.html\n",
    "\n",
    "Purpose: Predict total annual household income."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/samuel_harrold\n"
     ]
    }
   ],
   "source": [
    "cd ~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import standard packages.\n",
    "import os\n",
    "# Import installed packages.\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# Import local packages.\n",
    "# TODO: remove autoreload after testing.\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# IPython magic.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_static = os.path.join(os.path.expanduser(r'~'), r'stharrold.github.io/content/static')\n",
    "basename = r'20151230-predict-income-from-census'\n",
    "path_disk = os.path.abspath(r'/mnt/disk-20151227t211000z/')\n",
    "path_acs = os.path.join(path_disk, r'www2-census-gov/programs-surveys/acs/')\n",
    "path_hus = os.path.join(path_acs, r'data/pums/2013/5-Year/ss13husa.csv') # 'hus' = 'housing US'\n",
    "path_ddict = os.path.join(path_acs, r'tech_docs/pums/data_dict/PUMSDataDict13.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract-transform-load\n",
    "\n",
    "**TODO:**\n",
    "* Just use pandas. Acknowledge dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nrows = 127136\n",
      "df_acs RAM usage (MB) = 208.5\n",
      "CPU times: user 5.93 s, sys: 1.41 s, total: 7.34 s\n",
      "Wall time: 7.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "size_mem = 100e6 # limit ingested data to 100MB for this project\n",
    "with open(path_hus) as fobj:\n",
    "    nlines = sum(1 for _ in fobj)\n",
    "nrows = int(nlines * 100e6 / os.path.getsize(path_hus))\n",
    "print(\"nrows = {nrows}\".format(nrows=nrows))\n",
    "df_acs = pd.read_csv(path_hus, nrows=nrows)\n",
    "print(\"df_acs RAM usage (MB) = {mem:.1f}\".format(mem=df_acs.memory_usage().sum()/1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serialno</th>\n",
       "      <th>insp</th>\n",
       "      <th>RT</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>PUMA00</th>\n",
       "      <th>PUMA10</th>\n",
       "      <th>REGION</th>\n",
       "      <th>ST</th>\n",
       "      <th>ADJHSG</th>\n",
       "      <th>ADJINC</th>\n",
       "      <th>...</th>\n",
       "      <th>WGTP71</th>\n",
       "      <th>WGTP72</th>\n",
       "      <th>WGTP73</th>\n",
       "      <th>WGTP74</th>\n",
       "      <th>WGTP75</th>\n",
       "      <th>WGTP76</th>\n",
       "      <th>WGTP77</th>\n",
       "      <th>WGTP78</th>\n",
       "      <th>WGTP79</th>\n",
       "      <th>WGTP80</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.271360e+05</td>\n",
       "      <td>77104.000000</td>\n",
       "      <td>127136</td>\n",
       "      <td>127136.000000</td>\n",
       "      <td>127136.000000</td>\n",
       "      <td>127136.000000</td>\n",
       "      <td>127136.00000</td>\n",
       "      <td>127136.00000</td>\n",
       "      <td>127136.000000</td>\n",
       "      <td>127136.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>127136.000000</td>\n",
       "      <td>127136.000000</td>\n",
       "      <td>127136.000000</td>\n",
       "      <td>127136.000000</td>\n",
       "      <td>127136.000000</td>\n",
       "      <td>127136.000000</td>\n",
       "      <td>127136.000000</td>\n",
       "      <td>127136.000000</td>\n",
       "      <td>127136.000000</td>\n",
       "      <td>127136.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.010954e+12</td>\n",
       "      <td>822.495072</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.203971</td>\n",
       "      <td>771.943879</td>\n",
       "      <td>576.476041</td>\n",
       "      <td>3.06799</td>\n",
       "      <td>1.06799</td>\n",
       "      <td>1041979.809291</td>\n",
       "      <td>1050881.213236</td>\n",
       "      <td>...</td>\n",
       "      <td>18.386035</td>\n",
       "      <td>18.379287</td>\n",
       "      <td>18.363980</td>\n",
       "      <td>18.377934</td>\n",
       "      <td>18.377116</td>\n",
       "      <td>18.382079</td>\n",
       "      <td>18.374363</td>\n",
       "      <td>18.372184</td>\n",
       "      <td>18.377533</td>\n",
       "      <td>18.375818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.406006e+09</td>\n",
       "      <td>763.566754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.755190</td>\n",
       "      <td>876.894897</td>\n",
       "      <td>898.711496</td>\n",
       "      <td>0.25173</td>\n",
       "      <td>0.25173</td>\n",
       "      <td>32077.633446</td>\n",
       "      <td>29495.626547</td>\n",
       "      <td>...</td>\n",
       "      <td>20.923660</td>\n",
       "      <td>20.959673</td>\n",
       "      <td>20.751945</td>\n",
       "      <td>20.953753</td>\n",
       "      <td>20.758336</td>\n",
       "      <td>20.786674</td>\n",
       "      <td>20.857573</td>\n",
       "      <td>20.826727</td>\n",
       "      <td>20.669387</td>\n",
       "      <td>21.136350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.009000e+12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1007549.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.9%</th>\n",
       "      <td>2.009001e+12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1007549.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.011001e+12</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1035725.000000</td>\n",
       "      <td>1054614.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84.1%</th>\n",
       "      <td>2.013000e+12</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1086032.000000</td>\n",
       "      <td>1085467.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.013001e+12</td>\n",
       "      <td>5500.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2600.000000</td>\n",
       "      <td>2703.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>1086032.000000</td>\n",
       "      <td>1085467.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>445.000000</td>\n",
       "      <td>353.000000</td>\n",
       "      <td>437.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>381.000000</td>\n",
       "      <td>379.000000</td>\n",
       "      <td>445.000000</td>\n",
       "      <td>453.000000</td>\n",
       "      <td>432.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 205 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            serialno          insp      RT       DIVISION         PUMA00  \\\n",
       "count   1.271360e+05  77104.000000  127136  127136.000000  127136.000000   \n",
       "unique           NaN           NaN       1            NaN            NaN   \n",
       "top              NaN           NaN       H            NaN            NaN   \n",
       "freq             NaN           NaN  127136            NaN            NaN   \n",
       "mean    2.010954e+12    822.495072     NaN       6.203971     771.943879   \n",
       "std     1.406006e+09    763.566754     NaN       0.755190     876.894897   \n",
       "min     2.009000e+12      0.000000     NaN       6.000000      -9.000000   \n",
       "15.9%   2.009001e+12      0.000000     NaN       6.000000      -9.000000   \n",
       "50%     2.011001e+12    750.000000     NaN       6.000000     400.000000   \n",
       "84.1%   2.013000e+12   1300.000000     NaN       6.000000    1900.000000   \n",
       "max     2.013001e+12   5500.000000     NaN       9.000000    2600.000000   \n",
       "\n",
       "               PUMA10        REGION            ST          ADJHSG  \\\n",
       "count   127136.000000  127136.00000  127136.00000   127136.000000   \n",
       "unique            NaN           NaN           NaN             NaN   \n",
       "top               NaN           NaN           NaN             NaN   \n",
       "freq              NaN           NaN           NaN             NaN   \n",
       "mean       576.476041       3.06799       1.06799  1041979.809291   \n",
       "std        898.711496       0.25173       0.25173    32077.633446   \n",
       "min         -9.000000       3.00000       1.00000  1000000.000000   \n",
       "15.9%       -9.000000       3.00000       1.00000  1000000.000000   \n",
       "50%         -9.000000       3.00000       1.00000  1035725.000000   \n",
       "84.1%     1800.000000       3.00000       1.00000  1086032.000000   \n",
       "max       2703.000000       4.00000       2.00000  1086032.000000   \n",
       "\n",
       "                ADJINC      ...               WGTP71         WGTP72  \\\n",
       "count    127136.000000      ...        127136.000000  127136.000000   \n",
       "unique             NaN      ...                  NaN            NaN   \n",
       "top                NaN      ...                  NaN            NaN   \n",
       "freq               NaN      ...                  NaN            NaN   \n",
       "mean    1050881.213236      ...            18.386035      18.379287   \n",
       "std       29495.626547      ...            20.923660      20.959673   \n",
       "min     1007549.000000      ...           -21.000000       0.000000   \n",
       "15.9%   1007549.000000      ...             3.000000       3.000000   \n",
       "50%     1054614.000000      ...            13.000000      12.000000   \n",
       "84.1%   1085467.000000      ...            33.000000      33.000000   \n",
       "max     1085467.000000      ...           445.000000     353.000000   \n",
       "\n",
       "               WGTP73         WGTP74         WGTP75         WGTP76  \\\n",
       "count   127136.000000  127136.000000  127136.000000  127136.000000   \n",
       "unique            NaN            NaN            NaN            NaN   \n",
       "top               NaN            NaN            NaN            NaN   \n",
       "freq              NaN            NaN            NaN            NaN   \n",
       "mean        18.363980      18.377934      18.377116      18.382079   \n",
       "std         20.751945      20.953753      20.758336      20.786674   \n",
       "min          0.000000      -5.000000      -2.000000       0.000000   \n",
       "15.9%        3.000000       3.000000       3.000000       3.000000   \n",
       "50%         13.000000      12.000000      13.000000      13.000000   \n",
       "84.1%       33.000000      33.000000      33.000000      33.000000   \n",
       "max        437.000000     400.000000     420.000000     381.000000   \n",
       "\n",
       "               WGTP77         WGTP78         WGTP79         WGTP80  \n",
       "count   127136.000000  127136.000000  127136.000000  127136.000000  \n",
       "unique            NaN            NaN            NaN            NaN  \n",
       "top               NaN            NaN            NaN            NaN  \n",
       "freq              NaN            NaN            NaN            NaN  \n",
       "mean        18.374363      18.372184      18.377533      18.375818  \n",
       "std         20.857573      20.826727      20.669387      21.136350  \n",
       "min          0.000000       0.000000       0.000000       0.000000  \n",
       "15.9%        3.000000       3.000000       3.000000       3.000000  \n",
       "50%         13.000000      13.000000      13.000000      12.000000  \n",
       "84.1%       33.000000      33.000000      33.000000      33.000000  \n",
       "max        379.000000     445.000000     453.000000     432.000000  \n",
       "\n",
       "[11 rows x 205 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentiles = [0.1587, 0.5000, 0.8413] # +1 std. dev., mean/median, -1 std. dev. for normal dist.\n",
    "df_acs.describe(percentiles=percentiles, include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pdb on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Move to package.\n",
    "# TODO: use example data dict as test.\n",
    "# TODO: def ddict_to_json\n",
    "# Entries in the data dictionary are \"codes for variables\", using the ACS terminology.\n",
    "# https://www.census.gov/programs-surveys/acs/technical-documentation/pums/documentation.html\n",
    "# Example data dictionary: http://www2.census.gov/programs-surveys/acs/tech_docs/pums/data_dict/PUMSDataDict13.txt\n",
    "# The data dictionary is not all encoded in UTF-8. Replace encoding errors when found.\n",
    "ddict = dict()\n",
    "with open(path_ddict, encoding='utf-8', errors='replace') as fobj:\n",
    "    # TEST\n",
    "    nrows = 0\n",
    "    # Data dictionary name is line 1.\n",
    "    ddict['name'] = fobj.readline().strip()\n",
    "    # Data dictionary date is line 2.\n",
    "    ddict['date'] = fobj.readline().strip()    \n",
    "    # Initialize flags to catch lines.\n",
    "    catch_var_name = None\n",
    "    catch_var_desc = None\n",
    "    catch_var_code = None\n",
    "    for line in fobj:\n",
    "        line = line.strip()\n",
    "        # TEST: Only read first few records.\n",
    "        print(line)\n",
    "        nrows += 1\n",
    "        if nrows >= 400:\n",
    "            break\n",
    "        # Record type is section header 'HOUSING RECORD' or 'PERSON RECORD'.\n",
    "        if line.endswith('RECORD'):\n",
    "            record_type = line\n",
    "            ddict[record_type] = dict()\n",
    "        # Variable name is preceded by newline.\n",
    "        # Variable code is followed by newline.\n",
    "        elif line == '':    \n",
    "            catch_var_name = True\n",
    "            catch_var_code = False\n",
    "        # Variable name is 1 line.\n",
    "        # Variable name is followed by variable description.\n",
    "        elif catch_var_name and len(line.split()) == 2:\n",
    "            (var_name, var_len) = line.split()\n",
    "            ddict[record_type][var_name] = dict()\n",
    "            ddict[record_type][var_name]['length'] = var_len\n",
    "            catch_var_name = False\n",
    "            catch_var_desc = True\n",
    "        # Variable description is 1 line.\n",
    "        # Variable description is followed by variable code(s).\n",
    "        elif catch_var_desc:\n",
    "            var_desc = line\n",
    "            ddict[record_type][var_name]['description'] = var_desc\n",
    "            catch_var_desc = False\n",
    "            catch_var_code = True\n",
    "        # Variable code(s) is 1+ line:\n",
    "        #     00 .Vacant unit\n",
    "        #     01 .One person record (one person in household or  \n",
    "        #     .any person in group quarters)\n",
    "        #     02..20 .Number of person records (number of persons in\n",
    "        #     .household)\n",
    "        # Variable code(s) is followed by newline.\n",
    "        elif catch_var_code:\n",
    "            # Example case: \"01 .One person record (one person in household or\"\n",
    "            if not line.startswith('.'):\n",
    "                # Correct explicit instances of misformatted data.\n",
    "                try:\n",
    "                    (var_code, var_code_desc) = line.split(sep=' .', maxsplit=1)\n",
    "                    ddict[record_type][var_name][var_code] = var_code_desc\n",
    "                except ValueError as err:\n",
    "                    # Initialize flags to handle error cases.\n",
    "                    raise_err = True\n",
    "                    parsed_var_code = False\n",
    "                    if record_type == 'HOUSING_RECORD':\n",
    "                        # Case: For var_name = 'RWAT', 'RWATPR' the code and code description\n",
    "                        # are split with '. ' instead of ' .'\n",
    "                        #     9. Case is from ...\n",
    "                        if (var_name == 'RWAT' or var_name == 'RWATPR') and line.startswith('9. Case is from'):\n",
    "                            (var_code, var_code_desc) = line.split(sep='. ', maxsplit=1)\n",
    "                            raise_err = False\n",
    "                            parsed_var_code = True\n",
    "                        # Case: For var_name = 'SMP' the variable description is continued on the next line.\n",
    "                        #     Total payment on all second and junior mortgages and home equity loans\n",
    "                        #     (monthly amount)\n",
    "                        elif var_name == 'SMP' and line == '(monthly amount)':\n",
    "                            var_desc = line\n",
    "                            ddict[record_type][var_name]['description'] += ' '+var_desc\n",
    "                            raise_err = False\n",
    "                            parsed_var_code = False\n",
    "                        else:\n",
    "                            pass\n",
    "                    else:\n",
    "                        pass\n",
    "                    if raise_err:\n",
    "                        raise err\n",
    "                    if parsed_var_code:\n",
    "                        ddict[record_type][var_name][var_code] = var_code_desc\n",
    "            # Example case: \".any person in group quarters)\"\n",
    "            else:\n",
    "                var_code_desc = line.lstrip('.')\n",
    "                ddict[record_type][var_name][var_code] += ' '+var_code_desc\n",
    "        # Variable note is preceded by newline.\n",
    "        # Variable note is 1 line.\n",
    "        # Variable note is followed by newline.\n",
    "        elif line.startswith('Note:'):\n",
    "            var_note = line.lstrip('Note:').strip()\n",
    "            ddict[record_type][var_name]['note'] = var_note\n",
    "print('#'*80)\n",
    "ddict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err raised\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    (var_code, var_code_desc) = line.split(sep=' .', maxsplit=1)\n",
    "except ValueError as err:\n",
    "    print('err raised')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Export ipynb to html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_ipynb = os.path.join(path_static, basename, basename+'.ipynb')\n",
    "for template in ['basic', 'full']:\n",
    "    path_html = os.path.splitext(path_ipynb)[0]+'-'+template+'.html'\n",
    "    cmd = ['jupyter', 'nbconvert', '--to', 'html', '--template', template, path_ipynb, '--output', path_html]\n",
    "    print(' '.join(cmd))\n",
    "    subprocess.run(args=cmd, check=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
